% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/discriminantValidity.R
\name{discriminantValidity}
\alias{discriminantValidity}
\title{Calculate discriminant validity statistics}
\usage{
discriminantValidity(object, cutoff = 0.9, merge = FALSE, level = 0.95)
}
\arguments{
\item{object}{The lavaan model object provided after running the \code{cfa} 
function.}

\item{cutoff}{A cutoff to be used in the constrainded models in likelihood 
ratio tests.}

\item{merge}{Whether the constrained models should be constructed by merging 
two factors as one. Implies \code{cutoff} = 1.}

\item{level}{The confidence level required.}
}
\value{
A \code{data.frame} of latent variable correlation estimates, their 
confidence intervals, and a likelihood ratio tests against constrained models.
with the following attributes:
\describe{
 \item{baseline}{The baseline model after possible rescaling.}
 \item{constrained}{A \code{list} of the fitted constrained models
 used in the likelihood ratio test.}
}
}
\description{
Calculate discriminant validity statistics based on a fitted lavaan object
}
\details{
Evaluated on the measurement scale level, discriminant validity is commonly
evaluated by checking if each pair of latent correlations is sufficiently 
below one (in absolute value) that the latent variables can be thought of
representing two distinct construxts.

\code{discriminantValidity} function calculates two sets of statistics that 
are commonly used in discriminant validity evaluation. The first set is are
factor correlation estimates and their confidence intervals. The second set
is a series of nested model tests, where the baseline model is compared
against as set of constrained models that are constructed by constraining
each factor correlation to the specified cutoff one at a time.

The function assume that the \code{object} is set of confirmatory
factor analysis results where the latent variables are scaled by fixing their
variances to 1s. If the model is not a CFA model, the function will calculate
the statistics for the correlations of exogenous latent variables. If the
latent variables are scaled in some other way (e.g. fixing the first loadings),
the function issues a warnign and re-estimates the model with scaling that
produces correlation estimates.

The likelihood ratio tests are done by comparing the original baseline model
against more constrained alternatives. By default, these alternatives are 
constructed by fixing each correlation at a time to a cutoff value. The
typical purpose of this test is to demonstrate that the estimated factor 
correlation is well below the cutoff and a significant chi2 statistic
thus indicates support for discriminant validity. In some cases it is possible
that the original correlation estimate is greater than the cutoff. In this
case the chi2 test would constrain the correlation to be lower than where it
is estimated and the test does not make sense. When this happens, the likelihood
ratio test will be replaced by comparing the baseline model against itself.
For correlations that are estimated to be negative, a negation of the cutoff
is used in the constrained mode. 

Another alternative is to do a nested model comparison against a model where
two factors are merged as one by setting the \code{merge} argument to 
\code{TRUE}. In this comparison, the constrained model is constructed by
removing one of the correlated factors from the model and assigning its
indicators to the factor that remains in the model.
}
\examples{

library(lavaan)

HS.model <- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '

fit <- cfa(HS.model, data = HolzingerSwineford1939)
discriminantValidity(fit)
discriminantValidity(fit, merge = TRUE)

}
