### Terrence D. Jorgensen
### Last updated: 4 April 2017
### runMI creates lavaan.mi instead of lavaanStar,
### extending lavaanList class instead of lavaan class



## -----------------
## Class and Methods
## -----------------

#' Class for a lavaan Model Fitted to Multiple Imputations
#' 
#' This class extends the \code{\linkS4class{lavaanList}} class, created by
#' fitting a lavaan model to a list of data sets. In this case, the list of
#' data sets are multiple imputations of missing data.
#' 
#' 
#' @name lavaan.mi-class
#' @aliases lavaan.mi-class show,lavaan.mi-method summary,lavaan.mi-method
#' anova,lavaan.mi-method nobs,lavaan.mi-method coef,lavaan.mi-method
#' vcov,lavaan.mi-method fitted,lavaan.mi-method fitted.values,lavaan.mi-method
#' residuals,lavaan.mi-method resid,lavaan.mi-method
#' @docType class
#' @slot lavaanList_slots All slots from \code{\linkS4class{lavaanList}} are
#'  available, but \code{\link{runMI}} only populates a subset of the list 
#'  slots, some of them with custom information:
#' @slot DataList The \code{list} of imputed data sets
#' @slot SampleStatsList List of output from
#'  \code{\link[lavaan]{lavInspect}(fit, "sampstat")} applied to each fitted
#'  model
#' @slot ParTableList See \code{\linkS4class{lavaanList}}
#' @slot vcovList See \code{\linkS4class{lavaanList}}
#' @slot ParTableList See \code{\linkS4class{lavaanList}}
#' @slot testList \code{list} of estimated coefficients in matrix format (one
#'  per imputation)
#' @slot GLIST pooled \code{list} of coefficients in GLIST format
#' @slot seed \code{integer} seed set before running imputations
#' @slot imputeCall call from imputation (if used) stored as a \code{list} of
#'  arguments
#' @slot convergence \code{list} of \code{logical} vectors indicating whether,
#'  for each imputed data set, (1) the model converged on a solution, (2)
#'  \emph{SE}s could be calculated, (3) the (residual) covariance matrix of
#'  latent variables (\eqn{\Psi}) is non-positive-definite, and (4) the residual
#'  covariance matrix of observed variables (\eqn{\Theta}) is
#'  non-positive-definite.
#' 
#' @return
#' \item{coef}{\code{signature(object = "lavaan.mi", type = "free", labels = TRUE)}:
#'  See \code{\linkS4class{lavaan}}. Returns the pooled point estimates (i.e.,
#'  averaged across imputed data sets; see Rubin, 1987).}
#' \item{vcov}{\code{signature(object = "lavaan.mi",
#'  type = c("pooled","between","within"))}: Returns the pooled covariance
#'  matrix of parameter estimates (\code{type = "pooled"}, the default), the 
#'  within-imputations covariance matrix (\code{type = "within"}), or the 
#'  between-imputations covariance matrix (\code{type = "between"}). See Enders 
#'  (2010, ch. 8) for details.}
#' \item{fitted.values}{\code{signature(object = "lavaan.mi")}: See
#'  \code{\linkS4class{lavaan}}. Returns model-implied moments, evaluated at the
#'  pooled point estimates.}
#' \item{fitted}{\code{signature(object = "lavaan.mi")}:
#'   alias for \code{fitted.values}}
#' \item{residuals}{\code{signature(object = "lavaan.mi", type = c("raw","cor"))}:
#'  See \code{\linkS4class{lavaan}}. By default (\code{type = "raw"}), returns 
#'  the difference between the model-implied moments from \code{fitted.values} 
#'  and the pooled observed moments (i.e., averaged across imputed data sets). 
#'  Standardized residuals are also available, using Bollen's 
#'  (\code{type = "cor"} or \code{"cor.bollen"}) or Bentler's 
#'  (\code{type = "cor.bentler"}) formulas.}
#' \item{resid}{\code{signature(object = "lavaan.mi", type = c("raw","cor"))}:
#'  alias for \code{residuals}}
#' \item{nobs}{\code{signature(object = "lavaan.mi", total = TRUE)}: either
#'  the total (default) sample size or a vector of group sample sizes 
#'  (\code{total = FALSE}).}
#' \item{anova}{\code{signature(object = "lavaan.mi", h1 = NULL,
#'   test = c("D3","D2","D1"), asymptotic = FALSE, constraints = NULL,
#'   indices = FALSE, baseline = NULL)}: Returns a test of model fit, or a test
#'   of the difference in fit between nested models if \code{h1} is another
#'   \code{lavaan.mi} object, assuming \code{object} is nested in \code{h1}. If
#'   \code{asymptotic}, the returned test statistic will follow a \eqn{\chi^2}
#'   distribution in sufficiently large samples; otherwise, it will follow an
#'   \emph{F} distribution. If a robust test statistic is detected in the 
#'   \code{object} results (it is assumed the same was requested in \code{h1},
#'   if provided), then \code{asymptotic} will be set to \code{TRUE} and the 
#'   pooled test statistic will be scaled using the average scaling factor (and 
#'   average shift parameter or \emph{df}, if applicable) across imputations.
#'   
#'   The default test (\code{"D3"}, or any of \code{"mr", "Meng.Rubin",
#'   "likelihood", "LRT"}) is a pooled likeliehood-ratio test (see Enders, 2010,
#'   ch. 8); \code{test = "mplus"} implies \code{"D3"} and \code{asymptotic =
#'   TRUE} (see Asparouhov & Muthen, 2010). When using a non-likelihood 
#'   estimator (e.g., DWLS for categorical outcomes), \code{"D3"} is not 
#'   available, so the default is changed to \code{"D2"} (alias can be any of 
#'   \code{"lmrr", "Li.et.al", "pooled.wald"}), which returns a pooled test 
#'   statistic. \code{"D1"} is a Wald test calculated for constraints on the 
#'   pooled point estimates, using the pooled covariance matrix of parameter 
#'   estimates; see \code{\link[lavaan]{lavTestWald}} for details. \code{h1} is 
#'   ignored when \code{test = "D1"}, and \code{constraints} is ignored when 
#'   \code{test != "D1"}.
#'   
#'   When \code{indices = TRUE} and \code{is.null(h1)}, popular indices of 
#'   approximate fit (CFI, TLI/NNFI, RMSEA with CI, and SRMR) will be returned 
#'   for \code{object}; see \code{\link[lavaan]{fitMeasures}} for details. 
#'   Specific indices can be requested with a \code{character} vector (any of 
#'   \code{"mfi", "rmsea", "gammaHat", "rmr", "srmr", "cfi", "tli", "nnfi", 
#'   "rfi", "nfi", "pnfi", "ifi", "rni"}), or all available indices will be 
#'   returned if \code{indices = "all"}. A custom user-specified \code{baseline}
#'   model, fit using \code{runMI}, can be used to calculate incremental fit 
#'   indices (e.g., CFI, TLI). If \code{is.null(baseline)}, the default 
#'   independence model will be used.}
#' 
#' \item{show}{\code{signature(object = "lavaan.mi")}: returns a message about
#'  convergence rates and estimation problems (if applicable) across imputed 
#'  data sets.}
#' \item{summary}{\code{signature(object = "lavaan.mi", se = TRUE, ci = TRUE,
#'  level = .95, standardized = FALSE, rsquare = FALSE, fmi = FALSE, 
#'  add.attributes = TRUE)}: see \code{\link[lavaan]{parameterEstimates}} for 
#'  details. By default, \code{summary} returns pooled point and \emph{SE} 
#'  estimates, along with \emph{t} test statistics and associated \emph{df} and 
#'  \emph{p} value, and 95\% CI (control using the \code{ci} and \code{level} 
#'  arguments). Standardized solution(s) can also be requested by name 
#'  (\code{"std.lv"} or \code{"std.all"}) or both are returned with \code{TRUE}.
#'  \emph{R}-squared for endogenous variables can be requested, as well as the 
#'  Fraction Missing Information (FMI) for parameter estimates. By default, the 
#'  output will appear like \code{lavaan}'s \code{summary} output, but if 
#'  \code{add.attributes = FALSE}, the returned \code{data.frame} will resemble 
#'  the \code{parameterEstimates} output.}
#' 
#' @section Objects from the Class: See the \code{\link{runMI}} function for
#' details. Wrapper functions include \code{\link{lavaan.mi}},
#' \code{\link{cfa.mi}}, \code{\link{sem.mi}}, and \code{\link{growth.mi}}.
#' @author Terrence D. Jorgensen (University of Amsterdam;
#' \email{TJorgensen314@@gmail.com})
#' @references Asparouhov, T., & Muthen, B. (2010). \emph{Chi-square statistics
#' with multiple imputation}. Technical Report. Retrieved from
#' \url{www.statmodel.com}
#' 
#' Enders, C. K. (2010). \emph{Applied missing data analysis}. New York, NY:
#' Guilford.
#' 
#' Li, K.-H., Meng, X.-L., Raghunathan, T. E., & Rubin, D. B. (1991).
#' Significance levels from repeated p-values with multiply-imputed data.
#' \emph{Statistica Sinica, 1}(1), 65-92. Retrieved from
#' \url{http://www.jstor.org/stable/24303994}
#' 
#' Meng, X.-L., & Rubin, D. B. (1992). Performing likelihood ratio tests with
#' multiply-imputed data sets. \emph{Biometrika, 79}(1), 103-111. Retrieved
#' from \url{http://www.jstor.org/stable/2337151}
#' 
#' Rubin, D. B. (1987). \emph{Multiple imputation for nonresponse in surveys}.
#' New York, NY: Wiley.
#' @examples
#' 
#' ## See ?runMI help page
#' 
setClass("lavaan.mi", contains = "lavaanList",
         slots = c(coefList = "list",     # coefficients in matrix format
                   GLIST = "list",        # list of pooled coefs in GLIST format
                   seed = "integer",      # seed set before running imputations
                   imputeCall = "list"  , # store call from imputation, if used
                   convergence = "list")) # also check SEs and Heywood cases



#' @name lavaan.mi-class
#' @aliases show,lavaan.mi-method
setMethod("show", "lavaan.mi", function(object) {
  nData <- object@meta$ndat

  useImps <- sapply(object@convergence, "[[", i = "converged")
  nConverged <- sum(useImps)

  SE <- sapply(object@convergence, "[[", "SE")
  SE[is.na(SE)] <- FALSE

  Heywood.ov <- sapply(object@convergence, "[[", "Heywood.ov")
  Heywood.ov[is.na(Heywood.ov)] <- FALSE

  Heywood.lv <- sapply(object@convergence, "[[", "Heywood.lv")
  Heywood.lv[is.na(Heywood.lv)] <- FALSE

  cat('lavaan.mi object based on ', nData, ' imputed data sets. \n',
      'See class?lavaan.mi help page for available methods. \n\n',
      'Convergence information:\n', 'The model converged on ',
      nConverged, ' imputed data sets \n\n', sep = "")

  if (!all(SE)) cat('Standard errors could not be computed for data set(s)',
                    paste(which(!SE), collapse = ", "), '\nTry fitting the',
                    'model to the individual data set(s) to diagnose',
                    'problems. If they cannot be fixed, try inspecting the',
                    'imputations. It may be necessary to reimpute the data',
                    'with some restrictions imposed. \n\n')

  if (any(Heywood.ov | Heywood.lv))
    cat('Heywood cases detected for data set(s)',
        paste(which(Heywood.ov | Heywood.lv), collapse = ", "),
        '\nThese are not necessarily a cause for concern, unless a pooled',
        'estimate is also a Heywood case. \n\n')

  object
})



summary.lavaan.mi <- function(object, se = TRUE, ci = TRUE, level = .95,
                              standardized = FALSE, rsquare = FALSE,
                              fmi = FALSE, add.attributes = TRUE) {
  useImps <- sapply(object@convergence, "[[", i = "converged")
  m <- sum(useImps)
  ## extract parameter table with attributes for printing
  PT <- parTable(object)
  PE <- PT[ , c("lhs","op","rhs","block","group")]
  free <- PT$free > 0L | PT$op == ":="
  STDs <- !(PT$op %in% c("==","<",">"))

  PE$est <- rowMeans(sapply(object@ParTableList[useImps], "[[", i = "est"))

  if (lavListInspect(object, "options")$se == "none") {
    warning('pooled variances and tests unavailable when se="none" is requested')
    se <- FALSE
  }
  if (!se) fmi <- FALSE
  messPool <- paste0("Rubin's (1987) rules were used to pool point",
                     if (se) " and SE",
                     " estimates across ", m, " imputed data sets",
                     if (se) ", and to calculate degrees of freedom for each",
                     if (se) " parameter's t test and CI.",
                     "\n")
  if (se) {
    PE$se <- lavaan::lav_model_vcov_se(object@Model, lavpartable = object@ParTable,
                                       VCOV = getMethod("vcov","lavaan.mi")(object))
    PE$t[free] <- PE$est[free] / PE$se[free]
    ## calculate df for t test
    W <- rowMeans(sapply(object@ParTableList[useImps], "[[", i = "se")^2)
    B <- apply(sapply(object@ParTableList[useImps], "[[", i = "est"), 1, var)
    Bm <- B + B/m
    Tot <- W + Bm
    ## can't do finite-sample correction because Wald z tests have no df (see Enders, 2010, p. 231, eq. 8.13 & 8.14)
    PE$df[free] <- (m - 1) * (1 + W[free] / Bm[free])^2
    ## if DF are obscenely large, set them to infinity for pretty printing
    PE$df <- ifelse(PE$df > 9999, Inf, PE$df)
    PE$pvalue <- pt(-abs(PE$t), df = PE$df)*2
    if (ci) {
      crit <- qt(1 - (1 - level) / 2, df = PE$df)
      PE$ci.lower <- PE$est - crit * PE$se
      PE$ci.upper <- PE$est + crit * PE$se
      PE$ci.lower[!free] <- PE$ci.upper[!free] <- PE$est[!free]
    }
  }

  if (is.logical(standardized)) {
    if (standardized) {
      PE$std.lv[STDs] <- lavaan::standardizedSolution(object, se = FALSE,
                                                      type = "std.lv",
                                                      GLIST = object@GLIST,
                                                      est = PE$est)$est.std
      PE$std.all[STDs] <- lavaan::standardizedSolution(object, se = FALSE,
                                                       type = "std.all",
                                                       GLIST = object@GLIST,
                                                       est = PE$est)$est.std
    }
  } else if (as.character(standardized)[1] == "std.lv") {
    PE$std.lv[STDs] <- lavaan::standardizedSolution(object, se = FALSE,
                                                    type = "std.lv",
                                                    GLIST = object@GLIST,
                                                    est = PE$est)$est.std
  } else if (as.character(standardized)[1] == "std.all") {
    PE$std.all[STDs] <- lavaan::standardizedSolution(object, se = FALSE,
                                                     type = "std.all",
                                                     GLIST = object@GLIST,
                                                     est = PE$est)$est.std
  }
  if (fmi) {
    PE$fmi1[free] <- Bm[free] / Tot[free]
    PE$fmi2[free] <- (Bm[free] + 2 / (PE$df[free] + 3)) / Tot[free]
    PE$riv[free] <- Bm[free] / W[free] # (Enders, 2010, p. 226, eq. 8.10)
    # == PE$riv[free] <- PE$fmi1[free] / (1 - PE$fmi1[free])
    messFMI <- paste("FMI(2) adjusts for using few imputations, but can",
                     "exceed 1 when the df are very large, making it",
                     "uninterpretable. The RIV will exceed 1 whenever",
                     "between-imputation variance exceeds",
                     "within-imputation variance (when FMI(1) > 50%).\n\n")
  }
  ## fancy or not?
  if (add.attributes) {
    PE$label <- PT$label
    PE$exo <- 0L # because PT$exo must be when !fixed.x
    class(PE) <- c("lavaan.parameterEstimates","lavaan.data.frame","data.frame")
    attr(PE, "information") <- lavListInspect(object, "options")$information
    attr(PE, "se") <- lavListInspect(object, "options")$se
    attr(PE, "group.label") <- lavListInspect(object, "group.label")
    attr(PE, "missing") <- lavListInspect(object, "options")$missing
    cat(messPool)
    if (fmi) cat("\n", messFMI, sep = "")
  } else {
    ## if not, attach header
    class(PE) <- c("lavaan.data.frame","data.frame")
    attr(PE, "header") <- if (fmi) c(messPool, "\n", messFMI) else messPool
  }
  ## requested R-squared?
  endoNames <- c(lavaan::lavNames(object, "ov.nox"),
                 lavaan::lavNames(object, "lv.nox"))
  if (rsquare & length(endoNames)) {
    isEndo <- sapply(PE$lhs, function(x) x %in% endoNames)
    rsqPE <- PE[PE$lhs == PE$rhs & PE$op == "~~" & isEndo, ]
    rsqPE$op <- "r2"
    for (i in which(!sapply(colnames(PE),
                            function(x) x %in% c("lhs","op","rhs","block","group","est","exo")))) {
      rsqPE[ , i] <- NA
    }
    STD <- lavaan::standardizedSolution(object, se = FALSE, type = "std.all",
                                        GLIST = object@GLIST, est = PE$est)
    isEndoSTD <- sapply(STD$lhs, function(x) x %in% endoNames)
    std.all <- STD$est.std[STD$lhs == STD$rhs & STD$op == "~~" & isEndoSTD]
    rsqPE$est <- ifelse(std.all < 0, NA, 1 - std.all) # negative variances
    if (add.attributes) rsqPE$label <- ""
    PE <- rbind(PE, rsqPE)
  }

  getMethod("show", "lavaan.mi")(object)
  if (!add.attributes) PE <- PE[!(PE$op %in% c("==","<",">")), ]
  rownames(PE) <- NULL
  PE
}
#' @name lavaan.mi-class
#' @aliases summary,lavaan.mi-method
setMethod("summary", "lavaan.mi", summary.lavaan.mi)



#' @name lavaan.mi-class
#' @aliases nobs,lavaan.mi-method
setMethod("nobs", "lavaan.mi", function(object, total = TRUE) {
  if (total) return(lavListInspect(object, "ntotal"))
  N <- lavListInspect(object, "norig")
  if (length(N) > 1L) names(N) <- lavListInspect(object, "group.label")
  N
})



coef.lavaan.mi <- function(object, type = "free", labels = TRUE) {
  useImps <- sapply(object@convergence, "[[", i = "converged")
  PT <- parTable(object)
  if (type == "user" || type == "all") {
    type <- "user"
    idx <- 1:length(PT$lhs)
  } else if (type == "free") {
    ## FIXME: duplicated leftover from old way of handling EQ constraints?
    idx <- which(PT$free > 0L & !duplicated(PT$free))
  }
  ## extract coefficients for converged models
  coefList <- lapply(object@ParTableList[useImps], "[[", i = "est")
  out <- colMeans(do.call(rbind, coefList))[idx]
  ## attach names, set class
  if (labels) names(out) <- lavaan::lav_partable_labels(PT, type = type)
  class(out) <- c("lavaan.vector","numeric")
  out
}
#' @name lavaan.mi-class
#' @aliases coef,lavaan.mi-method
setMethod("coef", "lavaan.mi", coef.lavaan.mi)



vcov.lavaan.mi <- function(object, type = c("pooled","between","within")) {
  if (lavListInspect(object, "options")$se == "none") {
    warning('requested se="none", so only between-imputation (co)variance can',
            ' be computed')
    type <- "between"
  }
  PT <- parTable(object)
  npar <- max(PT$free) - sum(PT$op == "==")
  useImps <- sapply(object@convergence, "[[", i = "converged")
  m <- sum(useImps)
  type <- tolower(type[1])
  
  useSE <- sapply(object@convergence, "[[", i = "SE")
  useSE[is.na(useSE)] <- FALSE
  
  coefList <- lapply(object@ParTableList[useImps], "[[", i = "est")
  B <- cov(do.call(rbind, coefList)[ , PT$free > 0L & !duplicated(PT$free)])
  class(B) <- c("lavaan.matrix.symmetric","matrix")
  rownames(B) <- colnames(B) <- lavaan::lav_partable_labels(PT, type = "free")
  if (type == "between") return(B)
  
  W <- Reduce("+", lapply(object@vcovList[useSE], function(x) x$vcov)) / sum(useSE)
  class(W) <- c("lavaan.matrix.symmetric","matrix")
  dimnames(W) <- dimnames(B)
  if (type == "within") {
    return(W)
  } else if (type != "pooled") stop("'", type, "' is not a valid option for 'type'")
  
  if (!all(useImps == useSE))
    warning('Between-imputation covariance matrix based on estimated parameters',
            ' from ', m, ' converged solutions, but the mean within-imputation',
            ' covariance matrix based on ', sum(useSE), ' solutions for which',
            ' standard errors could be calculated.  Pooled total covariance',
            ' matrix is therefore based on different imputed data sets.')
  
  ## check whether equality constraints prevent inversion of W
  inv.W <- try(solve(W), silent = TRUE)
  if (class(inv.W) != "try-error") {
    ## relative increase in variance due to missing data
    r <- (1 + 1/m)/npar * sum(diag(B %*% inv.W)) # Enders (2010, p. 235) eqs. 8.20-21
    Total <- (1 + r) * W # FIXME: asked Yves for a hack, says it can't be inverted back to infoMat
  } else {
    ## less reliable, but constraints prevent inversion of W
    Total <- W + B + (1/m)*B ## Enders (2010, p. 235) eq. 8.19
  }
  ## return pooled variance
  Total
}
#' @name lavaan.mi-class
#' @aliases vcov,lavaan.mi-method
setMethod("vcov", "lavaan.mi", vcov.lavaan.mi)


D1 <- function(object, constraints = NULL, asymptotic = FALSE, verbose = FALSE) {
  ## "borrowed" lavTestWald()
  nImps <- sum(sapply(object@convergence, "[[", i = "converged"))
  if (nImps == 1L) stop("model did not converge on any imputations")
  if (is.null(constraints) || nchar(constraints) == 0L) stop("constraints are empty")

  # remove == constraints from parTable, save as list
  PT <- parTable(object)
  partable <- as.list(PT[PT$op != "==", ])
  if (sum(PT$op == "==") > 0L) {
    message("When the unrestricted model already has equality constraints,",
            " D1 requires 'asymptotic = TRUE', so an approximate chi-squared",
            " will be returned instead of an F test statistic. \n")
    asymptotic <- TRUE
  }

  # parse constraints
  FLAT <- lavaan::lavParseModelString( constraints )
  CON <- attr(FLAT, "constraints")
  LIST <- list()
  if (length(CON) > 0L) {
    lhs <- unlist(lapply(CON, "[[", i = "lhs"))
    op <- unlist(lapply(CON, "[[", i = "op"))
    rhs <- unlist(lapply(CON, "[[", i = "rhs"))
    LIST$lhs <- c(LIST$lhs, lhs) # FIXME: why concatenate with NULL?
    LIST$op  <- c(LIST$op,  op)
    LIST$rhs <- c(LIST$rhs, rhs)
  } else stop("no equality constraints found in constraints argument")

  # theta = free parameters only (equality-constrained allowed)
  theta <- getMethod("coef", "lavaan.mi")(object) #object@optim$x

  # build constraint function
  ceq.function <- lavaan::lav_partable_constraints_ceq(partable = partable,
                                                       con = LIST, debug = FALSE)
  # compute jacobian restrictions
  JAC <- try(lavaan::lav_func_jacobian_complex(func = ceq.function, x = theta),
             silent = TRUE)
  if (inherits(JAC, "try-error")) { # eg. pnorm()
    JAC <- lavaan::lav_func_jacobian_simple(func = ceq.function, x = theta)
  }
  if (verbose) {cat("Restriction matrix (jacobian):\n"); print(JAC); cat("\n")}

  # linear restriction
  theta.r <- ceq.function( theta )
  if (verbose) {cat("Restricted theta values:\n"); print(theta.r); cat("\n")}

  # get VCOV
  VCOV <- getMethod("vcov", "lavaan.mi")(object)

  # restricted vcov
  info.r  <- JAC %*% VCOV %*% t(JAC)

  # Wald test statistic
  test.stat <- as.numeric(t(theta.r) %*% solve( info.r ) %*% theta.r)

  # number of constraints (k in Enders (2010, p. 235) eqs. 8.23-25)
  DF <- nrow(JAC)

  if (asymptotic) {
    out <- c("chisq" = test.stat * DF, df = DF,
             pvalue = pchisq(test.stat * DF, df = DF, lower.tail = FALSE))
  } else {
    npar <- max(PT$free) - sum(PT$op == "==")
    W <- getMethod("vcov", "lavaan.mi")(object, type = "within")
    B <- getMethod("vcov", "lavaan.mi")(object, type = "between")
    ## relative increase in variance due to missing data
    ariv <- (1 + 1/nImps) * sum(diag(B %*% solve(W))) / npar
    ########### FIXME: can't invert with equality constraints.
    ##                 Asked Yves for a hack, says it can't be done

    ## calculate denominator DF for F statistic
    a <- DF*(nImps - 1)
    if (a > 4) {
      v2 <- 4 + (a - 4) * (1 + (1 - 2/a)*(1 / ariv))^2 # Enders (eq. 8.24)
    } else {
      v2 <- a*(1 + 1/DF) * (1 + 1/ariv)^2 / 2 # Enders (eq. 8.25)
    }
    out <- c("F" = test.stat, df1 = DF, df2 = v2,
             pvalue = pf(test.stat, df1 = DF, df2 = v2, lower.tail = FALSE))
  }

  class(out) <- c("lavaan.vector","numeric")
  out
}
D2 <- function(object, h1 = NULL, asymptotic = FALSE,
               robust = FALSE, scaleshift = FALSE) {
  useImps <- sapply(object@convergence, "[[", i = "converged")
  nImps <- sum(useImps)
  ## check for robust test
  test <- if (robust) 2L else 1L ## only included for simulation studies
  #test <- ifelse(lavListInspect(object, "options")$test == "standard", 1L, 2L)

  ## pool Wald tests
  if (is.null(h1)) {
    DF <- mean(sapply(object@testList[useImps], function(x) x[[test]][["df"]]))
    w <- sapply(object@testList[useImps], function(x) x[[test]][["stat"]])
  } else {
    DF0 <- mean(sapply(object@testList[useImps], function(x) x[[test]][["df"]]))
    DF1 <- mean(sapply(h1@testList[useImps], function(x) x[[test]][["df"]]))
    DF <- DF0 - DF1
    w0 <- sapply(object@testList[useImps], function(x) x[[test]][["stat"]])
    w1 <- sapply(h1@testList[useImps], function(x) x[[test]][["stat"]])
    w <- w0 - w1
  }
  w_bar <- mean(w)
  ariv <- (1 + 1/nImps) * var(sqrt(w))
  test.stat <- (w_bar/DF - ((nImps + 1) * ariv / (nImps - 1))) / (1 + ariv)
  if (test.stat < 0) test.stat <- 0
  if (asymptotic) {
    out <- c("chisq" = test.stat * DF, df = DF,
             pvalue = pchisq(test.stat * DF, df = DF, lower.tail = FALSE))
  } else {
    v3 <- DF^(-3 / nImps) * (nImps - 1) * (1 + (1 / ariv))^2
    out <- c("F" = test.stat, df1 = DF, df2 = v3,
             pvalue = pf(test.stat, df1 = DF, df2 = v3, lower.tail = FALSE))
  }
  if (is.null(h1)) {
    PT <- parTable(object)
    out <- c(out, npar = max(PT$free) - sum(PT$op == "=="),
             ntotal = lavListInspect(object, "ntotal"))
  }

  class(out) <- c("lavaan.vector","numeric")
  out
}
getLLs <- function(object) {
  meanstructure <- lavListInspect(object, "meanstructure")
  nG <- lavListInspect(object, "ngroups")
  group <- lavListInspect(object, "group")
  useImps <- sapply(object@convergence, "[[", i = "converged")
  nImps <- sum(useImps)
  m <- length(useImps)
  implied <- getMethod("fitted", "lavaan.mi")(object)
  ## Multiple groups?
  if (nG > 1L) {
    group.label <- lavListInspect(object, "group.label")
    varnames <- lavaan::lavNames(object, group = 1:nG) # in case order differs?
    names(varnames) <- group.label
    S <- lapply(implied, "[[", i = "cov")
    if (meanstructure) {
      M <- lapply(implied, "[[", i = "mean")
    } else {
      M <- list()
      for (g in group.label) {
        M[[g]] <- Reduce("+", lapply(lapply(object@SampleStatsList[useImps],
                                            "[[", i = g),   # Group g's list of means
                                     "[[", i = "mean")) / nImps # average them
      }
    }
    LL <- numeric(length = m)
    for (i in 1:m) {
      if (!useImps[i]) next
      LLg <- numeric(length = nG)
      names(LLg) <- group.label
      dd <- object@DataList[[i]]
      for (g in group.label) {
        LLg[g] <- sum(apply(as.matrix(dd[ dd[,group] == g, varnames[[g]]]),
                            MARGIN = 1, FUN = mnormt::dmnorm, log = TRUE,
                            mean = M[[g]], varcov = unclass(S[[g]])))
      }
      LL[i] <- sum(LLg)
    }
  } else {
    varnames <- lavaan::lavNames(object)
    S <- implied$cov
    M <- if (meanstructure) implied$mean else {
      Reduce("+", lapply(object@SampleStatsList[useImps], "[[", i = "mean")) / nImps
    }
    LL <- numeric(length = m)
    for (i in 1:m) {
      if (!useImps[i]) next
      LL[i] <- sum(apply(as.matrix(object@DataList[[i]][ , varnames]),
                         MARGIN = 1, FUN = mnormt::dmnorm,
                         mean = M, varcov = unclass(S), log = TRUE))
    }
  }
  LL
}
D3 <- function(object, h1 = NULL, asymptotic = FALSE) {
  N <- lavListInspect(object, "ntotal")
  nG <- lavListInspect(object, "ngroups")
  group <- lavListInspect(object, "group")
  useImps <- sapply(object@convergence, "[[", i = "converged")
  nImps <- sum(useImps)
  m <- length(object@testList)
  if (is.null(h1)) {
    DF <- object@testList[[ which(useImps)[1] ]][[1]][["df"]]
  } else {
    DF1 <- h1@testList[[ which(useImps)[1] ]][[1]][["df"]]
    DF0 <- object@testList[[ which(useImps)[1] ]][[1]][["df"]]
    DF <- DF0 - DF1
  }

  ## calculate m log-likelihoods under pooled H0 estimates
  LL0 <- getLLs(object)

  ## calculate m log-likelihoods under pooled H1 estimates
  if (is.null(h1)) {
    ## calculate log-likelihood under saturated model as alternative (H1)
    LL1 <- numeric(length = m)
    if (nG > 1L) {
      group.label <- lavListInspect(object, "group.label")
      varnames <- lavaan::lavNames(object, group = 1:nG) # in case order changes?
      names(varnames) <- group.label
      Ns <- lavListInspect(object, "nobs") # group sample sizes
      names(Ns) <- group.label
      S1 <- M1 <- list()
      for (g in group.label) {
        S1[[g]] <- Reduce("+", lapply(lapply(object@SampleStatsList[useImps],
                                             "[[", i = g),  # Group g's cov list
                                      "[[", i = "cov")) / nImps  # average them
        M1[[g]] <- Reduce("+", lapply(lapply(object@SampleStatsList[useImps],
                                             "[[", i = g),  # Group g's list of means
                                      "[[", i = "mean")) / nImps # average them
        if (lavListInspect(object, "options")$sample.cov.rescale) {
          S1[[g]] <- S1[[g]] * (Ns[g] - 1) / Ns[g]
        }
      }
      ## within 1:m, iterate over 1:nG
      for (i in 1:m) {
        if (!useImps[i]) next
        LL1g <- numeric(length = nG)
        names(LL1g) <- group.label
        dd <- object@DataList[[i]]
        for (g in group.label) {
          LL1g[g] <- sum(apply(as.matrix(dd[ dd[,group] == g, varnames[[g]]]),
                               MARGIN = 1, FUN = mnormt::dmnorm, log = TRUE,
                               mean = M1[[g]], varcov = unclass(S1[[g]])))
        }
        LL1[i] <- sum(LL1g)
      }
    } else {
      varnames <- lavaan::lavNames(object)
      S1 <- Reduce("+", lapply(object@SampleStatsList[useImps], "[[", i = "cov")) / nImps
      if (lavListInspect(object, "options")$sample.cov.rescale) S1 <- S1 * (N - 1) / N
      M1 <- Reduce("+", lapply(object@SampleStatsList[useImps], "[[", i = "mean")) / nImps
      for (i in 1:m) {
        if (!useImps[i]) next
        LL1[i] <- sum(apply(as.matrix(object@DataList[[i]][ , varnames]),
                            MARGIN = 1, FUN = mnormt::dmnorm,
                            mean = M1, varcov = unclass(S1), log = TRUE))
      }
    }
  } else LL1 <- getLLs(h1)

  ## calculate average of m LRTs
  LRT_con <- mean(-2*(LL0[useImps] - LL1[useImps]))
  ## average chisq across imputations
  LRT_bar <- mean(sapply(object@testList[useImps], function(x) x[[1]]$stat))
  ## calculate average relative increase in variance
  a <- DF*(nImps - 1)
  ariv <- ((nImps + 1) / a) * (LRT_bar - LRT_con)
  test.stat <- LRT_con / (DF*(1 + ariv))
  if (test.stat < 0) {
    message('Negative test statistic set to zero \n')
    test.stat <- 0
  }
  if (asymptotic) {
    out <- c("chisq" = test.stat * DF, df = DF,
             pvalue = pchisq(test.stat * DF, df = DF, lower.tail = FALSE))
  } else {
    ## F statistic
    if (a > 4) {
      v4 <- 4 + (a - 4) * (1 + (1 - (2 / a))*(1 / ariv))^2 # Enders (eq. 8.34)
    } else {
      v4 <- a*(1 + 1/DF)*(1 + 1/ariv)^2 / 2 # Enders (eq. 8.35)
      # v4 <- (DF + 1)*(m - 1)*(1 + (1 / ariv))^2 / 2 # Grund et al. (eq. 9)
    }
    out <- c("F" = test.stat, df1 = DF, df2 = v4,
             pvalue = pf(test.stat, df1 = DF, df2 = v4, lower.tail = FALSE))
  }
  ## add log-likelihood and AIC/BIC for target model
  if (is.null(h1)) {
    PT <- parTable(object)
    npar <- max(PT$free) - sum(PT$op == "==")
    if (lavListInspect(object, "options")$sample.cov.rescale) N <- N - nG
    out <- c(out, npar = npar, ntotal = lavListInspect(object, "ntotal"),
             logl = mean(LL0), unrestricted.logl = mean(LL1),
             aic = -2*mean(LL0) + 2*npar, bic = -2*mean(LL0) + npar*log(N),
             bic2 = -2*mean(LL0) + npar*log((N + 2) / 24))
    ## NOTE: Mplus reports the average of m likelihoods evaluated at the
    ##       m point estimates, not evaluated at the pooled point estimates.
    ##       Mplus also uses those to calcluate AIC and BIC.
  }

  class(out) <- c("lavaan.vector","numeric")
  out
}
robustify <- function(ChiSq, object, h1 = NULL) {
  useImps <- sapply(object@convergence, "[[", i = "converged")
  scaleshift <- lavListInspect(object, "options")$test == "scaled.shifted"

  d0 <- mean(sapply(object@testList[useImps], function(x) x[[2]][["df"]]))
  c0 <- mean(sapply(object@testList[useImps],
                    function(x) x[[2]][["scaling.factor"]]))
  if (!is.null(h1)) {
    d1 <- mean(sapply(h1@testList[useImps], function(x) x[[2]][["df"]]))
    c1 <- mean(sapply(h1@testList[useImps],
                      function(x) x[[2]][["scaling.factor"]]))
    delta_c <- (d0*c0 - d1*c1) / (d0 - d1)
    ChiSq["chisq.scaled"] <- ChiSq[["chisq"]] / delta_c
    ChiSq["df.scaled"] <- d0 - d1
    ChiSq["pvalue.scaled"] <- pchisq(ChiSq[["chisq.scaled"]],
                                     df = ChiSq[["df.scaled"]],
                                     lower.tail = FALSE)
    ChiSq["chisq.scaling.factor"] <- delta_c
  } else {
    ChiSq["chisq.scaled"] <- ChiSq[["chisq"]] / c0
    ChiSq["df.scaled"] <- d0
    if (scaleshift) {
      ## add shift parameter here (copy from below) or below
      shift <- mean(sapply(object@testList[useImps],
                           function(x) x[[2]][["shift.parameter"]]))
      ChiSq["chisq.scaled"] <- ChiSq[["chisq.scaled"]] + shift
      ChiSq["pvalue.scaled"] <- pchisq(ChiSq[["chisq.scaled"]],
                                       df = ChiSq[["df.scaled"]],
                                       lower.tail = FALSE)
      ChiSq["chisq.scaling.factor"] <- c0
      ChiSq["chisq.shift.parameter"] <- shift
    } else {
      ChiSq["pvalue.scaled"] <- pchisq(ChiSq[["chisq.scaled"]],
                                       df = ChiSq[["df.scaled"]],
                                       lower.tail = FALSE)
      ChiSq["chisq.scaling.factor"] <- c0
    }
  }
  ChiSq
}
#' @name lavaan.mi-class
#' @aliases anova,lavaan.mi-method
anova.lavaan.mi <- function(object, h1 = NULL,
                            test = c("D3","D2","D1"),
                            asymptotic = FALSE, constraints = NULL,
                            indices = FALSE, baseline = NULL) {
  useImps <- sapply(object@convergence, "[[", i = "converged")
  nImps <- sum(useImps)
  ## check class
  if (!is(object, "lavaan.mi")) stop("object is not class 'lavaan.mi'")
  if (!is.null(h1) & !is(object, "lavaan.mi")) stop("h1 is not class 'lavaan.mi'")
  
  ## Everything else obsolete if test = "D1"
  if (toupper(test[1]) == "D1") {
    if (!asymptotic) asymptotic <- TRUE ## FIXME: until W can be inverted with eq. constraints
    out <- D1(object = object, constraints = constraints, asymptotic = asymptotic)
    message('D1 (Wald test) calculated using pooled "',
            lavListInspect(object, "options")$se,
            '" asymptotic covariance matrix of model parameters')
    return(out)
  }
  
  ## check for robust
  robust <- lavListInspect(object, "options")$test != "standard"
  if (robust) asymptotic <- TRUE
  scaleshift <- lavListInspect(object, "options")$test == "scaled.shifted"
  if (scaleshift & !is.null(h1)) stop("Robust correction unavailable for model",
                                      " comparison when test = 'scaled.shifted'")
  ################### FIXME: unless possible to mimic DIFFTEST behavior?
  
  
  ## check request for fit indices
  incremental <- c("cfi","tli","nnfi","rfi","nfi","pnfi","ifi","rni")
  if (is.logical(indices)) {
    moreFit <- is.null(h1) & indices
    if (moreFit) indices <- c("cfi","tli","rmsea","srmr")
  } else if (is.character(indices)) {
    indices <- tolower(indices)
    moreFit <- is.null(h1) & indices %in% c(incremental, "all","mfi","rmsea",
                                            "gammaHat","rmr","srmr")
    if (moreFit & any(indices == "all")) {
      indices <- c(incremental, "mfi","rmsea","gammaHat","rmr","srmr")
    }
  } else indices <- moreFit <- FALSE
  ## fit baseline model if necessary
  if (moreFit & any(indices %in% incremental)) {
    if (is.null(baseline)) {
      PTb <- lavaan::lav_partable_independence(lavdata = object@Data,
                                               lavoptions = lavListInspect(object, "options"))
      baseFit <- runMI(model = PTb, data = object@DataList[useImps],
                       group = lavListInspect(object, "group"),
                       se = "none", # to save time
                       test = lavListInspect(object, "options")$test,
                       estimator = lavListInspect(object, "options")$estimator,
                       ordered = lavListInspect(object, "ordered"),
                       parameterization = lavListInspect(object,
                                                         "parameterization"))
    } else if (!is(baseline, "lavaan.mi")) {
      stop('User-supplied baseline model must be "lavaan.mi" class fit',
           ' to the same imputed data')
    } else baseFit <- baseline
    baseImps <- sapply(baseFit@convergence, "[[", i = "converged")
    if (!all(baseImps)) warning('baseline model did not converge for data set(s): ',
                                which(useImps)[!baseImps])
  }
  
  ## check DF
  DF0 <- object@testList[[ which(useImps)[1] ]][[1]][["df"]]
  if (!is.null(h1)) {
    if (!is(h1, "lavaan.mi")) stop("h1 is not class 'lavaan.mi'")
    DF1 <- h1@testList[[ which(useImps)[1] ]][[1]][["df"]]
    if (DF0 == DF1) stop("models have the equal degrees of freedom")
    if (DF0 < DF1) {
      H0 <- h1
      h1 <- object
      object <- H0
      H0 <- DF1
      DF1 <- DF0
      DF0 <- H0
    }
    DF <- DF0 - DF1
  } else DF <- DF0
  if (DF == 0) indices <- moreFit <- FALSE # arbitrary perfect fit, no indices
  if (moreFit) asymptotic <- TRUE
  
  ## check test options, backward compatibility?
  if (tolower(test[1]) == "mplus") {
    test <- "D3"
    asymptotic <- TRUE
  }
  if (tolower(test[1]) %in% c("mr","meng.rubin","likelihood","lrt")) test <- "D3"
  if (tolower(test[1]) %in% c("lmrr","li.et.al","pooled.wald")) test <- "D2"
  if (toupper(test[1]) == "D3" & !lavListInspect(object, "options")$estimator %in% c("ML","PML","FML")) {
    message('"D3" only available using maximum likelihood estimation. ',
            'Changed test to "D2".')
    test <- "D2"
  }
  ## calculate pooled test
  if (toupper(test[1]) == "D3") {
    ## check estimator
    if (lavListInspect(object, "options")$estimator != "ML")
      stop("D3 is only available using ML estimation")
    out <- D3(object = object, h1 = h1, asymptotic = asymptotic)
    if (any(indices %in% incremental)) baseOut <- D3(baseFit, asymptotic = TRUE)
  } else if (toupper(test[1]) == "D2") {
    out <- D2(object = object, h1 = h1, asymptotic = asymptotic)
    if (any(indices %in% incremental)) baseOut <- D2(baseFit, asymptotic = TRUE)
  }
  ## If test statistic is negative, return without any indices or robustness
  if (asymptotic & (moreFit | robust)) {
    if (out[["chisq"]] == 0) {
      message('Negative test statistic set to zero, so fit will appear to be ',
              'arbitrarily perfect.  Robust corrections and additional fit ',
              'indices are not returned because they are uninformative.\n')
      class(out) <- c("lavaan.vector","numeric")
      return(out)
    }
  }
  
  ## add robust statistics
  if (robust) {
    out <- robustify(ChiSq = out, object, h1)
    if (scaleshift) {
      extraWarn <- ' and shift parameter'
    } else if (lavListInspect(object, "options")$test == "mean.var.adjusted") {
      extraWarn <- ' and degrees of freedom'
    } else extraWarn <- ''
    message('Robust corrections are made to the naive (pooled) chi-squared',
            ' test statistic using the mean scaling factor', extraWarn,
            ' across ', nImps, ' imputations for which the model converged. \n')
  }
  
  ## add fit indices for single model
  if (moreFit) {
    X2 <- out[["chisq"]]
    if (robust) {
      X2.sc <- out[["chisq.scaled"]]
      DF.sc <- out[["df.scaled"]] ## for mean.var.adjusted, mean DF across imputations
      ch <- out[["chisq.scaling.factor"]] ## mean c_hat across imputations
      if (X2 < .Machine$double.eps && DF == 0) ch <- 0
      ## for RMSEA
      if ("rmsea" %in% indices) {
        d <- mean(sapply(object@testList[useImps],
                         function(x) sum(x[[2]][["trace.UGamma"]])))
        if (is.na(d) || d == 0) d <- NA # FIXME: only relevant when scaleshift?
      }
    }
    ## for CFI, TLI, etc.
    if (any(indices %in% incremental)) {
      bX2 <- baseOut[["chisq"]]
      bDF <- baseOut[["df"]]
      out <- c(out, baseline.chisq = bX2, baseline.df = bDF,
               baseline.pvalue = baseOut[["pvalue"]])
      if (robust) {
        baseOut <- robustify(ChiSq = baseOut, object = baseFit)
        out["baseline.chisq.scaled"] <- bX2.sc <- baseOut[["chisq.scaled"]]
        out["baseline.df.scaled"]    <- bDF.sc <- baseOut[["df.scaled"]]
        out["baseline.pvalue.scaled"] <- baseOut[["pvalue.scaled"]]
        cb <- baseOut[["chisq.scaling.factor"]]
        out["baseline.chisq.scaling.factor"] <- cb
      }
    }
  }
  if ("cfi" %in% indices) {
    t1 <- max(X2 - DF, 0)
    t2 <- max(X2 - DF, bX2 - bDF, 0)
    out["cfi"] <- if(t1 == 0 && t2 == 0) 1 else 1 - t1/t2
    if (robust) {
      ## scaled
      t1 <- max(X2.sc - DF.sc, 0)
      t2 <- max(X2.sc - DF.sc, bX2.sc - bDF.sc, 0)
      if (is.na(t1) || is.na(t2)) {
        out["cfi.scaled"] <- NA
      } else if (t1 == 0 && t2 == 0) {
        out["cfi.scaled"] <- 1
      } else out["cfi.scaled"] <- 1 - t1/t2
      ## Brosseau-Liard & Savalei MBR 2014, equation 15
      if (lavListInspect(object, "options")$test %in%
          c("satorra.bentler","yuan.bentler")) {
        t1 <- max(X2 - ch*DF, 0)
        t2 <- max(X2 - ch*DF, bX2 - cb*bDF, 0)
        if (is.na(t1) || is.na(t2)) {
          out["cfi.robust"] <- NA
        } else if (t1 == 0 && t2 == 0) {
          out["cfi.robust"] <- 1
        } else out["cfi.robust"] <- 1 - t1/t2
      }
    }
  }
  if ("rni" %in% indices) {
    t1 <- X2 - DF
    t2 <- bX2 - bDF
    out["rni"] <- if (t2 == 0) NA else 1 - t1/t2
    if (robust) {
      ## scaled
      t1 <- X2.sc - DF.sc
      t2 <- bX2.sc - bDF.sc
      if (is.na(t1) || is.na(t2)) {
        out["rni.scaled"] <- NA
      } else if (t2 == 0) {
        out["rni.scaled"] <- NA
      } else out["rni.scaled"] <- 1 - t1/t2
      ## Brosseau-Liard & Savalei MBR 2014, equation 15
      if (lavListInspect(object, "options")$test %in%
          c("satorra.bentler","yuan.bentler")) {
        t1 <- X2 - ch*DF
        t2 <- bX2 - cb*bDF
        if (is.na(t1) || is.na(t2)) {
          out["rni.robust"] <- NA
        } else if (t1 == 0 && t2 == 0) {
          out["rni.robust"] <- NA
        } else out["rni.robust"] <- 1 - t1/t2
      }
    }
  }
  if (any(indices %in% c("tli","nnfi"))) {
    t1 <- (X2 - DF)*bDF
    t2 <- (bX2 - bDF)*DF
    out["tli"] <- out["nnfi"] <- if (DF > 0) 1 - t1/t2 else 1
    if (robust) {
      ## scaled
      t1 <- (X2.sc - DF.sc)*bDF.sc
      t2 <- (bX2.sc - bDF.sc)*DF.sc
      if (is.na(t1) || is.na(t2)) {
        out["tli.scaled"] <- out["nnfi.scaled"] <- NA
      } else if (DF > 0 && t2 != 0) {
        out["tli.scaled"] <- out["nnfi.scaled"] <- 1 - t1/t2
      } else {
        out["tli.scaled"] <- out["nnfi.scaled"] <- 1
      }
      ## Brosseau-Liard & Savalei MBR 2014, equation 15
      if (lavListInspect(object, "options")$test %in%
          c("satorra.bentler","yuan.bentler")) {
        t1 <- (X2 - ch*DF)*bDF
        t2 <- (bX2 - cb*bDF)*DF
        if (is.na(t1) || is.na(t2)) {
          out["tli.robust"] <- out["nnfi.robust"] <- NA
        } else if (t1 == 0 && t2 == 0) {
          out["tli.robust"] <- out["nnfi.robust"] <- 1 - t1/t2
        } else out["tli.robust"] <- out["nnfi.robust"] <- 1
      }
    }
  }
  if ("rfi" %in% indices) {
    if (DF > 0) {
      t2 <- bX2 / bDF
      t1 <- t2 - X2/DF
      out["rfi"] <- if (t1 < 0 || t2 < 0) 1 else t1/t2
    } else out["rfi"] <- 1
    if (robust) {
      if (DF > 0) {
        t2 <- bX2.sc / bDF.sc
        t1 <- t2 - X2.sc/DF.sc
        out["rfi.scaled"] <- if (t1 < 0 || t2 < 0) 1 else t1/t2
      } else out["rfi.scaled"] <- 1
    }
  }
  if ("nfi" %in% indices) {
    if (DF > 0) {
      t1 <- bX2 - X2
      t2 <- bX2
      out["nfi"] <- t1 / t2
    } else out["nfi"] <- 1
    if (robust) out["nfi.scaled"] <- (bX2.sc - X2.sc) / bX2.sc
  }
  if ("pnfi" %in% indices) {
    t1 <- bX2 - X2
    t2 <- bX2
    out["pnfi"] <- (DF / bDF) * t1/t2
    if (robust) {
      t1 <- bX2.sc - X2.sc
      t2 <- bX2.sc
      out["pnfi.scaled"] <- (DF / bDF) * t1/t2
    }
  }
  if ("ifi" %in% indices) {
    t1 <- bX2 - X2
    t2 <- bX2 - DF
    out["ifi"] <- if (t2 < 0) 1 else t1/t2
    if (robust) {
      t1 <- bX2.sc - X2.sc
      t2 <- bX2.sc - DF.sc
      if (is.na(t2)) {
        out["ifi.scaled"] <- NA
      } else if (t2 < 0) {
        out["ifi.scaled"] <- 1
      } else out["ifi.scaled"] <- t1/t2
    }
  }
  
  N <- lavListInspect(object, "ntotal")
  Ns <- lavListInspect(object, "nobs")
  nG <- lavListInspect(object, "ngroups")
  nVars <- length(lavaan::lavNames(object))
  if (!(lavListInspect(object, "options")$likelihood == "normal" |
        lavListInspect(object, "options")$estimator %in% c("ML","PML","FML"))) {
    N <- N - nG
    Ns <- Ns - 1
  }
  
  if ("mfi" %in% indices) {
    out["mfi"] <- exp(-0.5 * (X2 - DF) / N)
  }
  
  if ("rmsea" %in% indices) {
    N.RMSEA <- max(N, X2*4) # FIXME: good strategy??
    
    if (is.na(X2) || is.na(DF)) {
      out["rmsea"] <- as.numeric(NA)
    } else if (DF > 0) {
      getLambda <- function(lambda, chi, df, p) pchisq(chi, df, ncp=lambda) - p
      
      out["rmsea"] <- sqrt( max(0, (X2/N)/DF - 1/N) ) * sqrt(nG)
      ## lower confidence limit
      if (getLambda(0, X2, DF, .95) < 0.0) out["rmsea.ci.lower"] <- 0 else {
        lambda.l <- try(uniroot(f = getLambda, chi = X2, df = DF, p = .95,
                                lower = 0, upper = X2)$root, silent = TRUE)
        if (inherits(lambda.l, "try-error")) lambda.l <- NA
        out["rmsea.ci.lower"] <- sqrt( lambda.l/(N*DF) ) * sqrt(nG)
      }
      ## upper confidence limit
      if (getLambda(N.RMSEA, X2, DF, .05) > 0 || getLambda(0, X2, DF, .05) < 0) {
        out["rmsea.ci.upper"] <- 0
      } else {
        lambda.u <- try(uniroot(f = getLambda, chi = X2, df = DF, p = .05,
                                lower = 0, upper = N.RMSEA)$root, silent = TRUE)
        if (inherits(lambda.u, "try-error")) lambda.u <- NA
        out["rmsea.ci.upper"] <- sqrt( lambda.u/(N*DF) ) * sqrt(nG)
      }
      ## p value
      out["rmsea.pvalue"] <- pchisq(X2, DF, ncp = N*DF*0.05^2/nG,
                                    lower.tail = FALSE)
      
      ## Scaled versions (naive and robust)
      if (robust & !scaleshift) {
        ## naive
        out["rmsea.scaled"] <- sqrt( max(0, (X2/N)/d - 1/N) ) * sqrt(nG)
        ## lower confidence limit
        if (DF.sc < 1 | getLambda(0, X2, DF.sc, .95) < 0.0) {
          out["rmsea.ci.lower.scaled"] <- 0
        } else {
          lambda.l <- try(uniroot(f = getLambda, chi = X2, df = DF.sc, p = .95,
                                  lower = 0, upper = X2)$root, silent = TRUE)
          if (inherits(lambda.l, "try-error")) lambda.l <- NA
          out["rmsea.ci.lower.scaled"] <- sqrt( lambda.l/(N*DF) ) * sqrt(nG)
        }
        ## upper confidence limit
        if (DF.sc < 1 | getLambda(N.RMSEA, X2, DF.sc, .05) > 0.0) {
          out["rmsea.ci.upper.scaled"] <- 0
        } else {
          lambda.u <- try(uniroot(f = getLambda, chi = X2, df = DF.sc, p = .05,
                                  lower = 0, upper = N.RMSEA)$root, silent = TRUE)
          if (inherits(lambda.u, "try-error")) lambda.u <- NA
          out["rmsea.ci.upper.scaled"] <- sqrt( lambda.u/(N*DF) ) * sqrt(nG)
        }
        ## p value
        out["rmsea.pvalue.scaled"] <- pchisq(X2, DF.sc, ncp = N*DF.sc*0.05^2/nG,
                                             lower.tail = FALSE)
        
        if (object@Options$test %in% c("satorra.bentler","yuan.bentler")) {
          ## robust
          out["rmsea.robust"] <- sqrt( max(0, (X2/N)/DF - ch/N ) ) * sqrt(nG)
          ## lower confidence limit
          if (DF.sc < 1 | getLambda(0, X2.sc, DF.sc, .95) < 0.0) {
            out["rmsea.ci.lower.robust"] <- 0
          } else {
            lambda.l <- try(uniroot(f = getLambda, chi = X2.sc, df = DF.sc, p = .95,
                                    lower = 0, upper = X2)$root, silent = TRUE)
            if (inherits(lambda.l, "try-error")) lambda.l <- NA
            out["rmsea.ci.lower.robust"] <- sqrt( (ch*lambda.l)/(N*DF.sc) ) * sqrt(nG)
          }
          ## upper confidence limit
          if (DF.sc < 1 | getLambda(N.RMSEA, X2.sc, DF.sc, .05) > 0.0) {
            out["rmsea.ci.upper.robust"] <- 0
          } else {
            lambda.u <- try(uniroot(f = getLambda, chi = X2.sc, df = DF.sc, p = .05,
                                    lower = 0, upper = N.RMSEA)$root, silent = TRUE)
            if (inherits(lambda.u, "try-error")) lambda.u <- NA
            out["rmsea.ci.upper.robust"] <- sqrt( (ch*lambda.u)/(N*DF.sc) ) * sqrt(nG)
          }
          ## p value
          ########## To be discovered?
        }
      } else if (scaleshift) {
        ## naive only
        out["rmsea.scaled"] <- sqrt( max(0, (X2.sc/N)/DF - 1/N) ) * sqrt(nG)
        ## lower confidence limit
        if (DF.sc < 1 | getLambda(0, X2.sc, DF.sc, .95) < 0.0) {
          out["rmsea.ci.lower.scaled"] <- 0
        } else {
          lambda.l <- try(uniroot(f = getLambda, chi = X2.sc, df = DF.sc, p = .95,
                                  lower = 0, upper = X2.sc)$root, silent = TRUE)
          if (inherits(lambda.l, "try-error")) lambda.l <- NA
          out["rmsea.ci.lower.scaled"] <- sqrt( lambda.l/(N*DF.sc) ) * sqrt(nG)
        }
        ## upper confidence limit
        if (DF.sc < 1 | getLambda(N.RMSEA, X2.sc, DF.sc, .05) > 0.0) {
          out["rmsea.ci.upper.scaled"] <- 0
        } else {
          lambda.u <- try(uniroot(f = getLambda, chi = X2.sc, df = DF.sc, p = .05,
                                  lower = 0, upper = N.RMSEA)$root, silent = TRUE)
          if (inherits(lambda.u, "try-error")) lambda.u <- NA
          out["rmsea.ci.upper.scaled"] <- sqrt( lambda.u/(N*DF.sc) ) * sqrt(nG)
        }
        ## p value
        out["rmsea.pvalue.scaled"] <- pchisq(X2.sc, DF.sc, ncp = N*DF.sc*0.05^2/nG,
                                             lower.tail = FALSE)
      }
    }
  }
  
  if ("gammaHat" %in% indices) {
    out["gammaHat"] <- nVars / (nVars + 2*((X2 - DF) / N))
    out["adjGammaHat"] <- 1 - (((nG * nVars * (nVars + 1)) / 2) / DF) * (1 - out["gammaHat"])
    if (robust) {
      out["gammaHat.scaled"] <- nVars / (nVars + 2*((X2.sc - DF.sc) / N))
      out["adjGammaHat.scaled"] <- 1 - (((nG * nVars * (nVars + 1)) / 2) / DF.sc) * (1 - out["gammaHat.scaled"])
    }
  }
  
  getSRMR <- function(object, type) {
    vv <- lavaan::lavNames(object, type = "ov.num")
    R <- getMethod("resid", "lavaan.mi")(object, type = type)
    index <- if (type == "raw") "cov" else "cor"
    if (nG > 1L) {
      RR <- list()
      for (g in 1:nG) {
        RR[[g]] <- c(R[[g]][[index]][lower.tri(R[[g]][[index]], diag = FALSE)]^2,
                     diag(R[[g]][[index]])[vv]^2)
      }
    } else RR <- c(R[[index]][lower.tri(R[[index]], diag = FALSE)]^2,
                   diag(R[[index]])[vv]^2)
    
    if (lavListInspect(object, "meanstructure")) {
      if (nG > 1L) {
        for (g in 1:nG) RR[[g]] <- c(RR[[g]], R[[g]]$mean[vv]^2)
      } else RR <- c(RR, R$mean[vv]^2)
    }
    
    SS <- if (nG > 1L) sqrt(sapply(RR, mean)) else sqrt(mean(RR))
    as.numeric( (lavListInspect(object, "nobs") %*% SS) / lavListInspect(object, "ntotal") )
  }
  if("rmr" %in% indices) out["rmr"] <- getSRMR(object, type = "raw")
  if("srmr" %in% indices) {
    out["srmr_bollen"] <- getSRMR(object, type = "cor.bollen")
    out["srmr_bentler"] <- getSRMR(object, type = "cor.bentler")
  }
  
  class(out) <- c("lavaan.vector","numeric")
  out # FIXME: in future, accept more than 2 models, arrange sequentially by DF
}
setMethod("anova", "lavaan.mi", anova.lavaan.mi)



## function to pool each group's list of sample stats
sampstat.lavaan.mi <- function(lst, means = FALSE, categ = FALSE, m = m) {
  ## average sample stats across imputations
  out <- list(cov = Reduce("+", lapply(lst, "[[", i = "cov")) / m)
  if (means) out$mean <- Reduce("+", lapply(lst, "[[", i = "mean")) / m
  if (categ) out$th <- Reduce("+", lapply(lst, "[[", i = "th")) / m
  out
}
fitted.lavaan.mi <- function(object) {
  useImps <- sapply(object@convergence, "[[", i = "converged")
  m <- sum(useImps)
  meanstructure <- lavListInspect(object, "meanstructure")
  categ <- lavListInspect(object, "categorical")
  nG <- lavListInspect(object, "ngroups")
  ov.names <- lavaan::lavNames(object)

  est <- getMethod("coef", "lavaan.mi")(object)
  imp <- lavaan::lav_model_implied(lavaan::lav_model_set_parameters(object@Model,
                                                                    x = est))
  out <- list()
  if (nG > 1L) {
    group.label <- lavListInspect(object, "group.label")
    for (i in seq_along(imp)) names(imp[[i]]) <- group.label
    for (g in group.label) {
      out[[g]]$cov <- imp$cov[[g]]
      dimnames(out[[g]]$cov) <- list(ov.names, ov.names)
      class(out[[g]]$cov) <- c("lavaan.matrix.symmetric","matrix")
      if (meanstructure) {
        out[[g]]$mean <- as.numeric(imp$mean[[g]])
        names(out[[g]]$mean) <- ov.names
        class(out[[g]]$mean) <- c("lavaan.vector","numeric")
      } else {
        out[[g]]$mean <- sampstat.lavaan.mi(lapply(object@SampleStatsList[useImps], "[[", g),
                                            means = TRUE, categ = categ, m = m)$mean
      }
      if (categ) {
        out[[g]]$th <- imp$th[[g]]
        names(out[[g]]$th) <- lavaan::lavNames(object, "th")
        class(out[[g]]$th) <- c("lavaan.vector","numeric")
      }
    }
  } else {
    out$cov <- imp$cov[[1]]
    dimnames(out$cov) <- list(ov.names, ov.names)
    class(out$cov) <- c("lavaan.matrix.symmetric","matrix")
    if (meanstructure) {
      out$mean <- as.numeric(imp$mean[[1]])
      names(out$mean) <- ov.names
      class(out$mean) <- c("lavaan.vector","numeric")
    } else {
      out$mean <- sampstat.lavaan.mi(object@SampleStatsList[useImps],
                                     means = TRUE, categ = categ, m = m)$mean
    }
    if (categ) {
      out$th <- imp$th[[1]]
      names(out$th) <- lavaan::lavNames(object, "th")
      class(out$th) <- c("lavaan.vector","numeric")
    }
  }
  out
}
#' @name lavaan.mi-class
#' @aliases fitted,lavaan.mi-method
setMethod("fitted", "lavaan.mi", fitted.lavaan.mi)
#' @name lavaan.mi-class
#' @aliases fitted.values,lavaan.mi-method
setMethod("fitted.values", "lavaan.mi", fitted.lavaan.mi)



## function to calculate residuals for one group
gp.resid.lavaan.mi <- function(Observed, N, Implied, type,
                               means = FALSE, categ = FALSE, m) {
  obsMats <- sampstat.lavaan.mi(Observed, means = means, categ = categ, m = m)
  ## average sample stats across imputations
  S_mean <- if (is.null(N)) obsMats$cov else (obsMats$cov * ((N - 1L) / N))
  if (means) M_mean <- obsMats$mean
  if (categ) Th_mean <- obsMats$th

  if (type == "raw") {
    out <- list(cov = S_mean - Implied$cov)
    if (means) out$mean <- M_mean - Implied$mean else {
      out$mean <- rep(0, nrow(out$cov))
      names(out$mean) <- rownames(out$cov)
    }
    if (categ) out$th <- Th_mean - Implied$th
    return(out)
  } else if (type == "cor.bollen") {
    out <- list(cor = cov2cor(S_mean) - cov2cor(Implied$cov))
    if (!means) {
      out$mean <- rep(0, nrow(out$cor))
      names(out$mean) <- rownames(out$cor)
    } else {
      std.obs.M <- M_mean / sqrt(diag(S_mean))
      std.mod.M <- Implied$mean / sqrt(diag(Implied$cov))
      out$mean <- std.obs.M - std.mod.M
    }
  } else if (type == "cor.bentler") {
    SDs <- diag(sqrt(diag(S_mean)))
    dimnames(SDs) <- dimnames(S_mean)
    out <- list(cor = solve(SDs) %*% (S_mean - Implied$cov) %*% solve(SDs))
    class(out$cor) <- c("lavaan.matrix.symmetric","matrix")
    if (!means) {
      out$mean <- rep(0, nrow(out$cor))
      names(out$mean) <- rownames(out$cor)
    } else out$mean <- (M_mean - Implied$mean) / diag(SDs)
  } else stop("argument 'type' must be 'raw', 'cor', 'cor.bollen', ",
              "or 'cor.bentler'.")
  if (categ) out$th <- Th_mean - Implied$th
  out
}
resid.lavaan.mi <- function(object, type = c("raw","cor")) {
  ## @SampleStatsList is (for each imputation) output from:
  ##    getSampStats <- function(obj) lavInspect(obj, "sampstat")
  useImps <- sapply(object@convergence, "[[", i = "converged")
  m <- sum(useImps)
  rescale <- lavListInspect(object, "options")$sample.cov.rescale
  meanstructure <- lavListInspect(object, "meanstructure")
  categ <- lavListInspect(object, "categorical")
  type <- tolower(type[1])
  ## check for type = "cor" ("cor.bollen") or "cor.bentler"
  if (type == "cor") type <- "cor.bollen"
  ## model-implied moments, already pooled
  Implied <- getMethod("fitted", "lavaan.mi")(object)
  ## Calculate residuals
  nG <- lavListInspect(object, "ngroups")
  N <- lavListInspect(object, "nobs")
  if (nG > 1L) {
    group.label <- names(Implied)
    if (is.null(group.label)) group.label <- 1:length(Implied) else names(N) <- group.label
    out <- list()
    for (g in group.label) {
      out[[g]] <- gp.resid.lavaan.mi(Observed = lapply(object@SampleStatsList[useImps], "[[", g),
                                     N = if (rescale) N[g] else NULL,
                                     Implied = Implied[[g]], type = type,
                                     means = meanstructure, m = m, categ = categ)
    }
  } else {
    out <- gp.resid.lavaan.mi(Observed = object@SampleStatsList[useImps],
                              N = if (rescale) N else NULL,
                              Implied = Implied, type = type,
                              means = meanstructure, m = m, categ = categ)
  }
  out
}
#' @name lavaan.mi-class
#' @aliases residuals,lavaan.mi-method
setMethod("residuals", "lavaan.mi", resid.lavaan.mi)
#' @name lavaan.mi-class
#' @aliases resid,lavaan.mi-method
setMethod("resid", "lavaan.mi", resid.lavaan.mi)



## ---------------------
## Constructor Functions
## ---------------------


#' Fit a lavaan Model to Multiple Imputed Data Sets
#' 
#' This function fits a lavaan model to a list of imputed data sets, and can
#' also implement multiple imputation for a single \code{data.frame} with
#' missing observations, using either the Amelia package or the mice package.
#' 
#' 
#' @aliases runMI lavaan.mi cfa.mi sem.mi growth.mi
#' @param model The analysis model can be specified using lavaan
#' \code{\link[lavaan]{model.syntax}} or a parameter table (as returned by
#' \code{\link[lavaan]{parTable}}).
#' @param data A \code{data.frame} with missing observations, or a \code{list}
#' of imputed data sets (if data are imputed already). If \code{runMI} has
#' already been called, then imputed data sets are stored in the
#' \code{@DataList} slot, so \code{data} can also be a \code{lavaan.mi} object
#' from which the same imputed data will be used for additional analyses.
#' @param fun \code{character}. Name of a specific lavaan function used to fit
#' \code{model} to \code{data} (i.e., \code{"lavaan"}, \code{"cfa"},
#' \code{"sem"}, or \code{"growth"}). Only required for \code{runMI}.
#' @param \dots additional arguments to pass to \code{\link[lavaan]{lavaan}} or
#' \code{\link[lavaan]{lavaanList}}. See also \code{\link[lavaan]{lavOptions}}.
#' Note that \code{lavaanList} provides parallel computing options, as well as
#' a \code{FUN} argument so the user can extract custom output after the model
#' is fitted to each imputed data set (see \strong{Examples}).  TIP: If a
#' custom \code{FUN} is used \emph{and} \code{parallel = "snow"} is requested,
#' the user-supplied function should explicitly call \code{library} or use
#' \code{\link[base]{::}} for any functions not part of the base distribution.
#' @param m \code{integer}. Request the number of imputations. Ignored if
#' \code{data} is already a \code{list} of imputed data sets or a
#' \code{lavaan.mi} object.
#' @param miArgs Addition arguments for the multiple-imputation function
#' (\code{miPackage}). The arguments should be put in a list (see example
#' below). Ignored if \code{data} is already a \code{list} of imputed data sets
#' or a \code{lavaan.mi} object.
#' @param miPackage Package to be used for imputation. Currently these
#' functions only support \code{"Amelia"} or \code{"mice"} for imputation.
#' Ignored if \code{data} is already a \code{list} of imputed data sets or a
#' \code{lavaan.mi} object.
#' @param seed \code{integer}. Random number seed to be set before imputing the
#'  data. Ignored if \code{data} is already a \code{list} of imputed data sets 
#'  or a \code{lavaan.mi} object.
#' @return A \code{\linkS4class{lavaan.mi}} object
#' @author Terrence D. Jorgensen (University of Amsterdam;
#' \email{TJorgensen314@@gmail.com})
#' @references Enders, C. K. (2010). \emph{Applied missing data analysis}. New
#' York, NY: Guilford.
#' 
#' Rubin, D. B. (1987). \emph{Multiple imputation for nonresponse in surveys}.
#' New York, NY: Wiley.
#' @examples
#'  \dontrun{
#' ## impose missing data for example
#' HSMiss <- HolzingerSwineford1939[ , c(paste("x", 1:9, sep = ""),
#'                                       "ageyr","agemo","school")]
#' set.seed(12345)
#' HSMiss$x5 <- ifelse(HSMiss$x5 <= quantile(HSMiss$x5, .3), NA, HSMiss$x5)
#' age <- HSMiss$ageyr + HSMiss$agemo/12
#' HSMiss$x9 <- ifelse(age <= quantile(age, .3), NA, HSMiss$x9)
#' 
#' ## specify CFA model from lavaan's ?cfa help page
#' HS.model <- '
#'   visual  =~ x1 + x2 + x3
#'   textual =~ x4 + x5 + x6
#'   speed   =~ x7 + x8 + x9
#' '
#' 
#' ## impute data within runMI...
#' out1 <- cfa.mi(HS.model, data = HSMiss, m = 20, seed = 12345,
#'                miArgs = list(noms = "school"))
#' 
#' ## ... or impute missing data first
#' library(Amelia)
#' set.seed(12345)
#' HS.amelia <- amelia(HSMiss, m = 20, noms = "school", p2s = FALSE)
#' imps <- HS.amelia$imputations
#' out2 <- cfa.mi(HS.model, data = imps)
#' 
#' ## same results (using the same seed results in the same imputations)
#' cbind(impute.within = coef(out1), impute.first = coef(out2))
#' 
#' summary(out1)
#' summary(out1, ci = FALSE, fmi = TRUE, add.attributes = FALSE)
#' summary(out1, ci = FALSE, stand = TRUE, rsq = TRUE)
#' 
#' ## model fit. D3 includes information criteria
#' anova(out1)
#' anova(out1, test = "D2", indices = TRUE) # request D2 and fit indices
#' 
#' 
#' 
#' ## fit multigroup model without invariance constraints
#' mgfit1 <- cfa.mi(HS.model, data = imps, estimator = "mlm", group = "school")
#' ## add invariance constraints, and use previous fit as "data"
#' mgfit0 <- cfa.mi(HS.model, data = mgfit1, estimator = "mlm", group = "school",
#'                  group.equal = c("loadings","intercepts"))
#' 
#' ## compare fit (scaled likelihood ratio test)
#' anova(mgfit0, h1 = mgfit1)
#' 
#' ## correlation residuals
#' resid(mgfit0, type = "cor.bentler")
#' 
#' 
#' ## use D1 to test a parametrically nested model (whether latent means are ==)
#' anova(mgfit0, test = "D1", constraints = '
#'       .p70. == 0
#'       .p71. == 0
#'       .p72. == 0')
#' 
#' 
#' 
#' ## ordered-categorical data
#' data(datCat)
#' lapply(datCat, class)
#' ## impose missing values
#' set.seed(123)
#' for (i in 1:8) datCat[sample(1:nrow(datCat), size = .1*nrow(datCat)), i] <- NA
#' 
#' catout <- cfa.mi(' f =~ u1 + u2 + u3 + u4 ', data = datCat,
#'                  m = 3, seed = 456,
#'                  miArgs = list(ords = paste0("u", 1:8), noms = "g"),
#'                  FUN = function(fit) {
#'                    list(wrmr = lavaan::fitMeasures(fit, "wrmr"),
#'                         zeroCells = lavaan::lavInspect(fit, "zero.cell.tables"))
#'                  })
#' summary(catout)
#' anova(catout, indices = "all") # note the scaled versions of indices, too
#' 
#' ## extract custom output
#' sapply(catout@funList, function(x) x$wrmr) # WRMR for each imputation
#' catout@funList[[1]]$zeroCells # zero-cell tables for first imputation
#' catout@funList[[2]]$zeroCells # zero-cell tables for second imputation ...
#' 
#' } 
#' 
runMI <- function(model, data, fun = "lavaan", ...,
                  m, miArgs = list(), miPackage = "Amelia", seed = 12345) {
  dots <- list(...)
  if (!is.null(dots$fixed.x)) {
    if (dots$fixed.x) warning('fixed.x set to FALSE')
  }
  if (!is.null(dots$conditional.x)) {
    if (dots$conditional.x) warning('conditional.x set to FALSE')
  }
  dots$fixed.x <- dots$conditional.x <- FALSE
  
  seed <- as.integer(seed[1])
  ## Create (or acknowledge) list of imputed data sets
  imputedData <- NULL
  if (is.data.frame(data)) {
    if (miPackage[1] == "Amelia") {
      requireNamespace("Amelia")
      if (!"package:Amelia" %in% search()) attachNamespace("Amelia")
      imputeCall <- c(list(Amelia::amelia, x = data, m = m, p2s = 0), miArgs)
      set.seed(seed)
      imputedData <- unclass(eval(as.call(imputeCall))$imputations)
    } else if (miPackage[1] == "mice") {
      requireNamespace("mice")
      if (!"package:mice" %in% search()) attachNamespace("mice")
      imputeCall <- c(list(mice::mice, data = data, m = m, diagnostics = FALSE,
                           printFlag = FALSE), miArgs)
      set.seed(seed)
      miceOut <- eval(as.call(imputeCall))
      imputedData <- list()
      for (i in 1:m) {
        imputedData[[i]] <- mice::complete(x = miceOut, action = i, include = FALSE)
      }
    } else stop("Currently runMI only supports imputation by Amelia or mice")
  } else if (is.list(data)) {
    seed <- integer(length = 0)
    imputeCall <- list()
    imputedData <- data
    m <- length(data)
    class(imputedData) <- "list" # override inheritance (e.g., "mi" if Amelia)
  } else if (is(data, "lavaan.mi")) {
    seed <- data@seed
    imputeCall <- data@imputeCall
    imputedData <- data@DataList
    m <- length(imputedData)
  } else stop("data is not a valid input type: a partially observed data.frame,",
              " a list of imputed data.frames, or previous lavaan.mi object")
  
  ## Function to get custom output for lavaan.mi object
  getOutput <- function(obj) {
    converged <- lavaan::lavInspect(obj, "converged")
    if (converged) {
      se <- lavaan::parTable(obj)$se
      se.test <- all(!is.na(se)) & all(se >= 0) & any(se != 0)
      if (lavaan::lavInspect(obj, "ngroups") == 1L) {
        Heywood.lv <- det(lavaan::lavInspect(obj, "cov.lv")) <= 0
        Heywood.ov <- det(lavaan::lavInspect(obj, "theta")) <= 0
      } else {
        Heywood.lv <- !all(sapply(lavaan::lavInspect(obj, "cov.lv"), det) > 0)
        Heywood.ov <- !all(sapply(lavaan::lavInspect(obj, "theta"), det) > 0)
      }
    } else {
      se.test <- Heywood.lv <- Heywood.ov <- NA
    }
    list(sampstat = lavaan::lavInspect(obj, "sampstat"),
         coefMats = lavaan::lavInspect(obj, "est"),
         GLIST = obj@Model@GLIST, # FIXME: @Model slot may disappear; need GLIST for std.all
         converged = converged, SE = se.test,
         Heywood.lv = Heywood.lv, Heywood.ov = Heywood.ov)
  }
  ## FIXME: in case of user-supplied FUN for lavaanList, combine with getOutput
  
  ## fit model using lavaanList
  lavListCall <- list(lavaan::lavaanList, model = model, dataList = imputedData,
                      cmd = fun)
  lavListCall <- c(lavListCall, dots)
  lavListCall$store.slots <- c("partable","vcov","test")
  lavListCall$FUN <- if (is.null(dots$FUN)) getOutput else function(obj) {
    temp1 <- getOutput(obj)
    temp2 <- dots$FUN(obj)
    if (!is.list(temp2)) temp2 <- list(userFUN1 = temp2)
    if (is.null(names(temp2))) names(temp2) <- paste0("userFUN", 1:length(temp2))
    duplicatedNames <- which(sapply(names(temp2), function(x) {
      x %in% c("sampstat","coefMats","converged",
               "SE","Heywood.lv","Heywood.ov","GLIST")
    }))
    for (i in duplicatedNames) names(temp2)[i] <- paste0("userFUN", i)
    c(temp1, temp2)
  }
  fit <- eval(as.call(lavListCall))
  ## Store custom @DataList and @SampleStatsList
  fit@SampleStatsList <- lapply(fit@funList, "[[", i = "sampstat")
  fit@DataList <- imputedData
  ## assign class and add new slots
  fit <- as(fit, "lavaan.mi")
  fit@coefList <- lapply(fit@funList, "[[", i = "coefMats")
  fit@seed <- seed
  fit@imputeCall <- imputeCall
  convList <- lapply(fit@funList, "[", i = c("converged","SE",
                                             "Heywood.lv","Heywood.ov"))
  nonConv <- which(sapply(convList, is.null))
  if (length(nonConv)) for (i in nonConv) {
    convList[[i]] <- list(converged = FALSE, SE = NA, Heywood.lv = NA, Heywood.ov = NA)
  }
  
  fit@convergence <- lapply(convList, function(x) do.call(c, x))
  conv <- which(sapply(fit@convergence, "[", i = "converged"))
  if (length(conv)) {
    firstConv <- conv[1]
    fit@GLIST <- list()
    ## loop over GLIST elements
    for (mat in seq_along(fit@funList[[firstConv]][["GLIST"]])) {
      matList <- lapply(fit@funList[conv], function(x) x$GLIST[[mat]])
      fit@GLIST[[mat]] <- Reduce("+", matList) / length(matList)
    }
    names(fit@GLIST) <- names(fit@funList[[firstConv]][["GLIST"]])
  } else {
    fit@GLIST <- list()
    warning('The model did not converge for any imputed data sets.')
  }
  
  ## keep any remaining funList slots (if allowing users to supply custom FUN)
  funNames <- names(fit@funList[[1]])
  keepIndex <- which(!sapply(funNames, function(x) {
    x %in% c("sampstat","coefMats","converged",
             "SE","Heywood.lv","Heywood.ov","GLIST")
  }))
  if (length(keepIndex)) {
    fit@funList <- lapply(fit@funList, "[", i = keepIndex)
    if (length(keepIndex) > 1L) {
      keepNames <- funNames[keepIndex]
      noNames <- which(keepNames == "")
      for (i in seq_along(noNames)) keepNames[ noNames[i] ] <- paste0("userFUN", i)
      fit@funList <- lapply(fit@funList, "names<-", value = keepNames)
    }
  } else fit@funList <- list()
  
  fit@ParTable$start <- getMethod("coef", "lavaan.mi")(fit, type = "user", labels = FALSE)
  fit
}

#' @rdname runMI
lavaan.mi <- function(model, data, ...,
                      m, miArgs = list(), miPackage = "Amelia", seed = 12345) {
  runMI(model = model, data = data, fun = "lavaan", ...,
        m = m, miArgs = miArgs, miPackage = miPackage, seed = seed)
}

#' @rdname runMI
cfa.mi <- function(model, data, ...,
                   m, miArgs = list(), miPackage = "Amelia", seed = 12345) {
  runMI(model = model, data = data, fun = "cfa", ...,
        m = m, miArgs = miArgs, miPackage = miPackage, seed = seed)
}

#' @rdname runMI
sem.mi <- function(model, data, ...,
                   m, miArgs = list(), miPackage = "Amelia", seed = 12345) {
  runMI(model = model, data = data, fun = "sem", ...,
        m = m, miArgs = miArgs, miPackage = miPackage, seed = seed)
}

#' @rdname runMI
growth.mi <- function(model, data, ...,
                      m, miArgs = list(), miPackage = "Amelia", seed = 12345) {
  runMI(model = model, data = data, fun = "growth", ...,
        m = m, miArgs = miArgs, miPackage = miPackage, seed = seed)
}

